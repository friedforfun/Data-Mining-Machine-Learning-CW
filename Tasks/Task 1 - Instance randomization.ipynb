{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Randomization\n",
    "Produce versions of the above files that have the instances in a\n",
    "randomised order."
   ]
  },
  {
   "source": [
    "## Problem: our data sample needs to keep the matching y column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions from helperfn.py\n",
    "import helperfn as load_data\n",
    "\n",
    "# Jupyter notebook magic to auto reload the module when it gets changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((9690, 2304), (9690, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Example of how to get randomised data from a file in the 'Data' folder\n",
    "x, y = load_data.get_random_data(-1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:  [-0.32273189 -0.32363839 -0.31997007 ... -0.49734489 -0.49363907\n -0.49487499]\nmin:  -1.0\nmax:  1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Data normalized between 0 and 1\n",
    "zero_to_one_data = raw_data / 255\n",
    "# print(normalized_data)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# See https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "import numpy as np\n",
    "\n",
    "# scaled with https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "min_max_data = min_max_scaler.fit_transform(raw_data)\n",
    "print(\"mean: \", min_max_data.mean(axis=0))\n",
    "print(\"min: \", min_max_data.min())\n",
    "print(\"max: \", min_max_data.max())\n",
    "#print(min_max_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:  [-2.73144653e-17  2.52979612e-17  2.32814570e-17 ...  2.30981385e-17\n  1.09991136e-17 -4.17966315e-17]\nmin:  -1.7051161058250688\nmax:  4.668295812485869\n"
     ]
    }
   ],
   "source": [
    "# Scaled with https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale\n",
    "\n",
    "scaled_data = preprocessing.scale(raw_data)\n",
    "#print(scaled_data)\n",
    "print(\"mean: \", scaled_data.mean(axis=0))\n",
    "print(\"min: \", scaled_data.min())\n",
    "print(\"max: \", scaled_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we should use data stratification from lecture 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- NO LONGER USED --------------------------------------\n",
    "# -------------- SEE CELLS 1,2 FOR IMPORTING DATA ---------------------\n",
    "#import pandas\n",
    "#import os.path\n",
    "\n",
    "#def _get_random_data(filepath):\n",
    "#    \"\"\"Use get_random_data() instead. \n",
    "#    Get Dataframe with randomized instance order, takes filepath as arg\"\"\"\n",
    "#    df = pandas.read_csv(filepath)\n",
    "#    return df.sample(frac=1)\n",
    "\n",
    "#def _get_file_path(filename):\n",
    "#    \"\"\"Construct the filepath string, takes name of file as arg\"\"\"\n",
    "#    my_path = os.path.abspath(os.path.dirname(\"Data/\"))\n",
    "#    return os.path.join(my_path, filename)\n",
    "\n",
    "\n",
    "#def get_random_data(filename):\n",
    "#    \"\"\"Get Dataframe with randomized instance order, takes filename as arg\"\"\"\n",
    "#    return _get_random_data(_get_file_path(filename))\n",
    "\n",
    "# --------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions from helperfn.py\n",
    "import Scripts.helperfn as hf\n",
    "\n",
    "# Jupyter notebook magic to auto reload the module when it gets changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = hf.get_data_noresults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8219      5.0\n",
       "8218      5.0\n",
       "8217      5.0\n",
       "8216      5.0\n",
       "8214      6.0\n",
       "        ...  \n",
       "2948    255.0\n",
       "2949    255.0\n",
       "2951    255.0\n",
       "2909    255.0\n",
       "2382    255.0\n",
       "Name: 0, Length: 9690, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "raw_data['0'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "6*10\n",
    "#(5+1)*10-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def efb(column, num_bins=None):\n",
    "    if num_bins is None:\n",
    "        # Proportional k-interval discretization\n",
    "        num_bins = int(math.ceil(math.sqrt(data.shape[0])))\n",
    "\n",
    "    column = column.sort_values()\n",
    "    for i in range(bins):\n",
    "        current_bin = (0, 0)\n",
    "        if i*bins == 0:\n",
    "            current_bin[0] = 0\n",
    "        else:\n",
    "            current_bin[0] = column[i*bins]\n",
    "        if (i+1)*bins-1 < column.shape[0]:\n",
    "            curren_bin[1] = column[(i+1)*bins-1]\n",
    "        else: current_bin[1] = column[column.shape[0]-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efb(column, num_bins=None):\n",
    "    if num_bins is None:\n",
    "        # Proportional k-interval discretization\n",
    "        num_bins = int(math.ceil(math.sqrt(data.shape[0])))\n",
    "    np.zeros(num_bins, dtype=int)\n",
    "    column = column.sort_values()\n",
    "    expected_size = int(math.ceil(column.shape[0]/num_bins))\n",
    "    number_in_bin = 0\n",
    "\n",
    "    bins = [] \n",
    "\n",
    "    for i in range(column.shape[0]):\n",
    "        if number_in_bin >= expected_size and column[i] != column[i-1]:\n",
    "            # column i-1 becomes end label of current bin\n",
    "            # move to next bin\n",
    "            column[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "enter the data\n",
      "enter the number of bins\n",
      "number of data in each bin\n",
      "4\n",
      "index 0 old value  3.0 new value  1.0\n",
      "index 1 old value  1.0 new value  1.0\n",
      "index 2 old value  4.0 new value  6.0\n",
      "index 3 old value  6.0 new value  6.0\n",
      "index 4 old value  7.0 new value  8.0\n",
      "index 5 old value  0.0 new value  0.0\n",
      "index 6 old value  8.0 new value  8.0\n",
      "index 7 old value  7.0 new value  8.0\n",
      "index 8 old value  6.0 new value  6.0\n",
      "index 9 old value  3.0 new value  3.0\n",
      "index 10 old value  4.0 new value  3.0\n",
      "index 11 old value  5.0 new value  6.0\n",
      "index 12 old value  1.0 new value  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "#from sklearn.linear_model import LinearRegression \n",
    "#from sklearn import linear_model \n",
    "# import statsmodels.api as sm \n",
    "#import statistics \n",
    "import math \n",
    "from collections import OrderedDict \n",
    "  \n",
    "x = [] \n",
    "print(\"enter the data\") \n",
    "x = list(map(float, input().split())) \n",
    "  \n",
    "print(\"enter the number of bins\") \n",
    "bi = int(input()) \n",
    "  \n",
    "# X_dict will store the data in sorted order \n",
    "X_dict = OrderedDict() \n",
    "# x_old will store the original data \n",
    "x_old ={} \n",
    "# x_new will store the data after binning \n",
    "x_new ={} \n",
    "  \n",
    "  \n",
    "for i in range(len(x)): \n",
    "    X_dict[i]= x[i] \n",
    "    x_old[i]= x[i] \n",
    "  \n",
    "x_dict = sorted(X_dict.items(), key = lambda x: x[1]) \n",
    "  \n",
    "# list of lists(bins) \n",
    "binn =[] \n",
    "# a variable to find the mean of each bin \n",
    "avrg =[] \n",
    "  \n",
    "i = 0\n",
    "k = 0\n",
    "num_of_data_in_each_bin = int(math.ceil(len(x)/bi)) \n",
    "  \n",
    "for g, h in X_dict.items(): \n",
    "    if(i<num_of_data_in_each_bin): \n",
    "        avrg.append(h) \n",
    "        i = i + 1\n",
    "    elif(i == num_of_data_in_each_bin): \n",
    "        k = k + 1\n",
    "        i = 0\n",
    "        binn.append([min(avrg), max(avrg)]) \n",
    "        avrg =[] \n",
    "        avrg.append(h) \n",
    "        i = i + 1\n",
    "binn.append([min(avrg), max(avrg)]) \n",
    "  \n",
    "i = 0\n",
    "j = 0\n",
    "  \n",
    "for g, h in X_dict.items(): \n",
    "    if(i<num_of_data_in_each_bin): \n",
    "        if(abs(h-binn[j][0]) >= abs(h-binn[j][1])): \n",
    "            x_new[g]= binn[j][1] \n",
    "            i = i + 1\n",
    "        else: \n",
    "            x_new[g]= binn[j][0] \n",
    "            i = i + 1\n",
    "    else: \n",
    "        i = 0\n",
    "        j = j + 1\n",
    "        if(abs(h-binn[j][0]) >= abs(h-binn[j][1])): \n",
    "            x_new[g]= binn[j][1] \n",
    "        else: \n",
    "            x_new[g]= binn[j][0] \n",
    "        i = i + 1\n",
    "  \n",
    "print(\"number of data in each bin\") \n",
    "print(math.ceil(len(x)/bi)) \n",
    "for i in range(0, len(x)): \n",
    "    print('index {2} old value  {0} new value  {1}'.format(x_old[i], x_new[i], i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}